# ğŸ’³ Reducing Credit Default Rate at Bank

**Author:** Gaurav Yadav  
**Technologies:** Python Â· Pandas Â· Scikit-learn Â· SMOTE Â· XGBoost Â· Matplotlib Â· Seaborn

---

## ğŸ¯ Goal

The objective of this project is to identify **risky customers** who are likely to default on their loans and recommend proactive actions to reduce the **overall credit default rate** at ABC Bank.

---

## ğŸ¦ Background

ABC Bank has been facing challenges due to high credit default rates.  
To tackle this, the bank aims to:
- Detect customers with high default probability.
- Take **proactive measures** to prevent defaults before they occur.
- Use **data-driven decision-making** to reduce financial risk.

---

## ğŸ§  Methodology â€“ Solution Approach

The project involves the following major steps:

### ğŸ”¹ Step 1: Load the Dataset
- Loaded using Python (Pandas).
- Checked for **missing values** and explored feature details.

### ğŸ”¹ Step 2: Preprocessing and Feature Engineering
- Checked class distribution (imbalance found).
- Separated **numerical and categorical features**.
- Performed **EDA** on both types.
- Selected important numerical features using:
  - Extra Trees Regressor  
  - Correlation Matrix  
- Applied **StandardScaler** to numerical features.
- Chose categorical features based on **domain knowledge**.

### ğŸ”¹ Step 3: One-Hot Encoding
- One-hot encoded categorical variables.
- Handled **dummy variable trap**.

### ğŸ”¹ Step 4: Handling Imbalanced Data
- Used **SMOTE (Synthetic Minority Over-sampling Technique)** to balance the classes.

### ğŸ”¹ Step 5: Model Creation
- Combined processed numerical and encoded categorical features.
- Split the data into **train/test sets**.
- Trained multiple models:
  - Logistic Regression  
  - Decision Tree  
  - Random Forest  
  - XGBoost

### ğŸ”¹ Step 6: Model Evaluation
- Compared models using:
  - Accuracy  
  - Precision  
  - Recall  
  - F1-Score

---

## ğŸ§ª Modeling Techniques

- **Logistic Regression** â€“ Baseline binary classifier.
- **Decision Tree** â€“ Interpretable model with logical rules.
- **Random Forest** â€“ Ensemble of decision trees for better generalization.
- **XGBoost** â€“ Gradient boosting framework offering high performance.

> More technical details are available in the Jupyter notebook and presentation.

---

## ğŸ“ Files Included

- `data.xlsx` â€“ Dataset used for modeling.  
- `code.ipynb` â€“ Complete code with EDA, preprocessing, modeling, and evaluation.  
- `Analysis_Result.pptx` â€“ Visual analysis and model performance summary.  

---

## â–¶ï¸ How to Run the Project

1. Clone the repository or download the files.
2. Install required dependencies (you can use pip or conda):

```bash
pip install pandas scikit-learn xgboost imbalanced-learn matplotlib seaborn
